{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_z_WvptX8gP"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import random, grad, vmap, jit, hessian, lax\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.nn import relu\n",
        "from jax import config\n",
        "#from jax.ops import index_update, index # solo se usa en el solver de DR\n",
        "from jax.flatten_util import ravel_pytree\n",
        "\n",
        "import itertools\n",
        "from functools import partial\n",
        "from torch.utils import data\n",
        "from tqdm import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.interpolate import griddata\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generator\n",
        "class DataGenerator(data.Dataset):\n",
        "    def __init__(self, u, y, s,\n",
        "                 batch_size=64, rng_key=random.PRNGKey(1234)):\n",
        "        'Initialization'\n",
        "        self.u = u # input sample\n",
        "        self.y = y # location\n",
        "        self.s = s # labeled data evulated at y (solution measurements, BC/IC conditions, etc.)\n",
        "\n",
        "        self.N = u.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.key = rng_key\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        self.key, subkey = random.split(self.key)\n",
        "        inputs, outputs = self.__data_generation(subkey)\n",
        "        return inputs, outputs\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def __data_generation(self, key):\n",
        "        'Generates data containing batch_size samples'\n",
        "        idx = random.choice(key, self.N, (self.batch_size,), replace=False)\n",
        "        s = self.s[idx,:]\n",
        "        y = self.y[idx,:]\n",
        "        u = self.u[idx,:]\n",
        "        # Construct batch\n",
        "        inputs = (u, y)\n",
        "        outputs = s\n",
        "        return inputs, outputs"
      ],
      "metadata": {
        "id": "FaAeRgne6g1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural net\n",
        "def MLP(layers, activation=relu):\n",
        "  ''' Vanilla MLP'''\n",
        "  def init(rng_key):\n",
        "      def init_layer(key, d_in, d_out):\n",
        "          k1, k2 = random.split(key)\n",
        "          glorot_stddev = 1. / np.sqrt((d_in + d_out) / 2.)\n",
        "          W = glorot_stddev * random.normal(k1, (d_in, d_out))\n",
        "          b = np.zeros(d_out)\n",
        "          return W, b\n",
        "      key, *keys = random.split(rng_key, len(layers))\n",
        "      params = list(map(init_layer, keys, layers[:-1], layers[1:]))\n",
        "      return params\n",
        "  def apply(params, inputs):\n",
        "      for W, b in params[:-1]:\n",
        "          outputs = np.dot(inputs, W) + b\n",
        "          inputs = activation(outputs)\n",
        "      W, b = params[-1]\n",
        "      outputs = np.dot(inputs, W) + b\n",
        "      return outputs\n",
        "  return init, apply"
      ],
      "metadata": {
        "id": "6s1jFBV66sF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Nx, Nz = 70, 70\n",
        "\n",
        "# Define the model\n",
        "class PI_DeepONet:\n",
        "    def __init__(self, branch_layers, trunk_layers):\n",
        "        # Network initialization and evaluation functions\n",
        "        self.branch_init, self.branch_apply = MLP(branch_layers, activation=np.tanh)\n",
        "        self.trunk_init, self.trunk_apply = MLP(trunk_layers, activation=np.tanh)\n",
        "\n",
        "        # Initialize\n",
        "        branch_params = self.branch_init(rng_key = random.PRNGKey(1234))\n",
        "        trunk_params = self.trunk_init(rng_key = random.PRNGKey(4321))\n",
        "        params = (branch_params, trunk_params)\n",
        "\n",
        "        # Use optimizers to set optimizer initialization and update functions\n",
        "        self.opt_init, \\\n",
        "        self.opt_update, \\\n",
        "        self.get_params = optimizers.adam(optimizers.exponential_decay(1e-3,\n",
        "                                                                      decay_steps=2000,\n",
        "                                                                      decay_rate=0.9))\n",
        "        self.opt_state = self.opt_init(params)\n",
        "\n",
        "        # Used to restore the trained model parameters\n",
        "        _, self.unravel_params = ravel_pytree(params)\n",
        "\n",
        "        self.itercount = itertools.count()\n",
        "\n",
        "        # Loggers\n",
        "        self.loss_log = []\n",
        "        self.loss_bcs_log = []\n",
        "        self.loss_res_log = []\n",
        "\n",
        "    # Define DeepONet architecture\n",
        "    def operator_net(self, params, u, x, t):\n",
        "        branch_params, trunk_params = params\n",
        "        y = np.stack([x, t])\n",
        "        B = self.branch_apply(branch_params, u)\n",
        "        T = self.trunk_apply(trunk_params, y)\n",
        "        outputs = np.sum(B * T)\n",
        "        return  outputs\n",
        "\n",
        "    # Define ODE/PDE residual\n",
        "    def residual_net(self, params, u, xzt):\n",
        "        # xzt = (x, z, t)\n",
        "        x, z, t = xzt\n",
        "\n",
        "        # p(x,z,t) predicho por el DeepONet\n",
        "        p = self.operator_net(params, u, xzt)\n",
        "\n",
        "        # Primeras derivadas\n",
        "        dp_dx  = grad(self.operator_net, argnums=2)(params, u, xzt)[0]\n",
        "        dp_dz  = grad(self.operator_net, argnums=2)(params, u, xzt)[1]\n",
        "        dp_dt  = grad(self.operator_net, argnums=2)(params, u, xzt)[2]\n",
        "\n",
        "        # Segundas derivadas\n",
        "        def second_derivative(f, arg):\n",
        "            return grad(lambda X: grad(f, argnums=arg)(params, u, X))(xzt)[arg]\n",
        "\n",
        "        p_xx = second_derivative(self.operator_net, arg=0)\n",
        "        p_zz = second_derivative(self.operator_net, arg=1)\n",
        "        p_tt = second_derivative(self.operator_net, arg=2)\n",
        "\n",
        "        def get_c_from_u(u, x, z):\n",
        "            c_grid = u.reshape(Nz, Nx)  # por ejemplo\n",
        "            i = nearest_index(x_mesh, x)\n",
        "            j = nearest_index(z_mesh, z)\n",
        "            return c_grid[j, i]\n",
        "\n",
        "        # Velocidad local del medio\n",
        "        c = get_c_from_u(u, x, z)\n",
        "\n",
        "        # Residual de la ecuaci√≥n de onda\n",
        "        r = (1.0 / c**2) * p_tt - (p_xx + p_zz)\n",
        "\n",
        "        return r\n",
        "\n",
        "    # Define boundary loss\n",
        "    def loss_bcs(self, params, batch):\n",
        "        inputs, outputs = batch\n",
        "        u, y = inputs\n",
        "\n",
        "        # Compute forward pass\n",
        "        s_pred = vmap(self.operator_net, (None, 0, 0, 0))(params, u, y[:,0], y[:,1])\n",
        "\n",
        "        # Compute loss\n",
        "        loss = np.mean((outputs.flatten() - s_pred)**2)\n",
        "        return loss\n",
        "\n",
        "    # Define residual loss\n",
        "    def loss_res(self, params, batch):\n",
        "        # Fetch data\n",
        "        # inputs: (u1, y), shape = (Nxm, m), (Nxm,1)\n",
        "        # outputs: u2, shape = (Nxm, 1)\n",
        "        inputs, outputs = batch\n",
        "        u, y = inputs\n",
        "        # Compute forward pass\n",
        "        pred = vmap(self.residual_net, (None, 0, 0, 0))(params, u, y[:,0], y[:,1])\n",
        "\n",
        "        # Compute loss\n",
        "        loss = np.mean((outputs.flatten() - pred)**2)\n",
        "        return loss\n",
        "\n",
        "    # Define total loss\n",
        "    def loss(self, params, bcs_batch, res_batch):\n",
        "        loss_bcs = self.loss_bcs(params, bcs_batch)\n",
        "        loss_res = self.loss_res(params, res_batch)\n",
        "        loss = loss_bcs + loss_res\n",
        "        return loss\n",
        "\n",
        "    # Define a compiled update step\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def step(self, i, opt_state, bcs_batch, res_batch):\n",
        "        params = self.get_params(opt_state)\n",
        "        g = grad(self.loss)(params, bcs_batch, res_batch)\n",
        "        return self.opt_update(i, g, opt_state)\n",
        "\n",
        "    # Optimize parameters in a loop\n",
        "    def train(self, bcs_dataset, res_dataset, nIter = 10000):\n",
        "        # Define data iterators\n",
        "        bcs_data = iter(bcs_dataset)\n",
        "        res_data = iter(res_dataset)\n",
        "\n",
        "        pbar = trange(nIter)\n",
        "        # Main training loop\n",
        "        for it in pbar:\n",
        "            # Fetch data\n",
        "            bcs_batch= next(bcs_data)\n",
        "            res_batch = next(res_data)\n",
        "\n",
        "            self.opt_state = self.step(next(self.itercount), self.opt_state, bcs_batch, res_batch)\n",
        "\n",
        "            if it % 100 == 0:\n",
        "                params = self.get_params(self.opt_state)\n",
        "\n",
        "                # Compute losses\n",
        "                loss_value = self.loss(params, bcs_batch, res_batch)\n",
        "                loss_bcs_value = self.loss_bcs(params, bcs_batch)\n",
        "                loss_res_value = self.loss_res(params, res_batch)\n",
        "\n",
        "                # Store losses\n",
        "                self.loss_log.append(loss_value)\n",
        "                self.loss_bcs_log.append(loss_bcs_value)\n",
        "                self.loss_res_log.append(loss_res_value)\n",
        "\n",
        "                # Print losses\n",
        "                pbar.set_postfix({'Loss': loss_value,\n",
        "                                  'loss_bcs' : loss_bcs_value,\n",
        "                                  'loss_physics': loss_res_value})\n",
        "\n",
        "    # Evaluates predictions at test points\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def predict_s(self, params, U_star, Y_star):\n",
        "        s_pred = vmap(self.operator_net, (None, 0, 0, 0))(params, U_star, Y_star[:,0], Y_star[:,1])\n",
        "        return s_pred\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def predict_res(self, params, U_star, Y_star):\n",
        "        r_pred = vmap(self.residual_net, (None, 0, 0, 0))(params, U_star, Y_star[:,0], Y_star[:,1])\n",
        "        return r_pred"
      ],
      "metadata": {
        "id": "gmcewCpi7D_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgIVB-3D693S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}